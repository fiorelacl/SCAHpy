[
  {
    "objectID": "es/index.html",
    "href": "es/index.html",
    "title": "Bienvenido ✨!",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision."
  },
  {
    "objectID": "es/index.html#qué-es-scahpy",
    "href": "es/index.html#qué-es-scahpy",
    "title": "Bienvenido ✨!",
    "section": "¿Qué es SCAHpy?",
    "text": "¿Qué es SCAHpy?\nSCAHpy es un paquete de Python de código abierto desarrollado como herramienta de posprocesamiento para los componentes atmosférico, oceánico e hidrológico del Modelo del Sistema Terrestre Regional (Regional Earth System Model) que cubre el territorio peruano y el océano Pacífico.\nEste modelo, denominado IGP-RESM-COW v1, fue implementado por el Instituto Geofísico del Perú (IGP) sobre la base del modelo atmosférico WRF, el modelo oceánico CROCO y el acoplador OASIS."
  },
  {
    "objectID": "es/index.html#por-qué-scahpy",
    "href": "es/index.html#por-qué-scahpy",
    "title": "Bienvenido ✨!",
    "section": "¿Por qué SCAHpy?",
    "text": "¿Por qué SCAHpy?\nEl paquete SCAHpy fue creado para abordar el desafío que representa el procesamiento de los grandes volúmenes de datos generados por el modelo IGP-RESM-COW.\nEste modelo, con su componente atmosférico basado en WRF, produce cantidades masivas de información durante las simulaciones, lo que demanda un tiempo considerable para su análisis.\nSCAHpy agiliza este proceso homogeneizando coordenadas y dimensiones, garantizando la compatibilidad y facilitando el análisis de los datos.\nAl simplificar la manipulación y preparación de la información, reduce significativamente el tiempo requerido para el posprocesamiento científico."
  },
  {
    "objectID": "es/index.html#cómo-usar-scahpy",
    "href": "es/index.html#cómo-usar-scahpy",
    "title": "Bienvenido ✨!",
    "section": "¿Cómo usar SCAHpy?",
    "text": "¿Cómo usar SCAHpy?\nSCAHpy puede emplearse como un paquete independiente.\nPara más detalles, consulta la sección Uso y los tutoriales que se presentan a continuación.\n\n\n\n\n\n\nNote\n\n\n\nSCAHpy ha sido desarrollado y probado con las salidas del modelo IGP-RESM-COW v1.\nSin embargo, está diseñado para trabajar con cualquier salida del modelo WRF.\n¡Estamos abiertos a contribuciones de la comunidad!\n\n\n\nPrimeros pasos\n\nInstalación\nUso\n\n\n\nTutoriales\n\nLectura de archivos individuales\nLectura de múltiples archivos\nVariables en niveles de presión\n\n\n\nAyuda y referencias\n\nReferencia de la API\nContribución"
  },
  {
    "objectID": "es/05_contrib.html",
    "href": "es/05_contrib.html",
    "title": "Contributing",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.\n\n\n\n\n\n\nContributing\nAll types of crontributions, bugs, feedbacks are welcome!\nReport bugs and submit feedback at Github Issues."
  },
  {
    "objectID": "es/03_tutorial_03.html",
    "href": "es/03_tutorial_03.html",
    "title": "Pressure levels variables",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision."
  },
  {
    "objectID": "es/03_tutorial_03.html#step-1-reading-wrf-data",
    "href": "es/03_tutorial_03.html#step-1-reading-wrf-data",
    "title": "Pressure levels variables",
    "section": "Step 1: Reading WRF Data",
    "text": "Step 1: Reading WRF Data\nWe initiate the process by listing all the files we want to read using the glob package and assigning them to the variable list_files.\nlist_files = sorted(glob.glob('/data/datos/COW/OUT_DIAG_WRF/wrfouts/wrfout_d01_*'))\nGiven the capability to specify excluded variables when reading netCDF files using the drop_variables argument (refer to xarray functions open_dataset and open_mfdataset), we utilize the _drop_vars function from the module in_out. This function takes the list of variables we require and generates a list containing all variables present in the output file, subsequently removing those we are not interested in (such as ‘P’, ‘PB’, ‘U’, ‘W’, ‘QVAPOR’). For this purpose, we use the first file from our list of files, assigning it to the variable dvars.\ndvars = in_out._drop_vars(list_files[0], ['P', 'PB', 'U', 'W', 'QVAPOR'], model='wrf')\nSubsequently, we utilize the read_wrf_multi function to selectively read the variables of interest. This function accepts the input path (file_name in this case), the list of variables to be excluded (dvars), any required time difference (e.g., '5 hours'), and the corresponding sign of the time difference (-1 for negative, 1 for positive). The outcome is an xarray.Dataset containing longitude, latitude, bottom_top, time, and the specified variables. Optionally, you can designate a save path to export the netCDF.\nds = in_out.read_wrf_multi(list_files, dvars, '5 hours', -1)"
  },
  {
    "objectID": "es/03_tutorial_03.html#step-2-calculating-specific-humidity-and-total-pressure",
    "href": "es/03_tutorial_03.html#step-2-calculating-specific-humidity-and-total-pressure",
    "title": "Pressure levels variables",
    "section": "Step 2: Calculating Specific Humidity and Total pressure",
    "text": "Step 2: Calculating Specific Humidity and Total pressure\nIn this step, we will utilize the met_diag module to calculate specific humidity (calc_qe), and total pressure (calc_pres). Whe have the option of the parameter elimthat can be set to True or False in order to remove some variables used to calculate the final variable.\nds_lvl = met_vars.calc_qe(ds, elim=True)\nds_lvl = met_vars.calc_pres(ds_lvl, elim=True)\nBy running these commands, we ensure that our dataset ds_lvl now contains calculated specific humidity and total pressure, ready for further analysis or visualization."
  },
  {
    "objectID": "es/03_tutorial_03.html#step-3-aggregating-the-data",
    "href": "es/03_tutorial_03.html#step-3-aggregating-the-data",
    "title": "Pressure levels variables",
    "section": "Step 3: Aggregating the Data",
    "text": "Step 3: Aggregating the Data\nNow, we’ll aggregate the data to operate on a daily time scale instead of hourly. To achieve this, we’ll utilize the dmy_var function from the temp_scales module. This function takes an xarray.Dataset as input, where we specify the desired time scale (e.g., ‘1D’ for daily, ‘ME’ for monthly, ‘YE’ for yearly). Additionally, we can specify which variables should be aggregated by sum, average, or median by providing lists for each aggregation method.\ndd = temp_scales.dmy_var(ds_lvl, tiempo='1D', accum=None, avg=['Presion','U','W','QE'], mediana=None)\nBy executing this code, we’ll have our data aggregated to a daily time scale, with variables averaged according to our specifications."
  },
  {
    "objectID": "es/03_tutorial_03.html#step-4-interpolation-to-vertical-levels",
    "href": "es/03_tutorial_03.html#step-4-interpolation-to-vertical-levels",
    "title": "Pressure levels variables",
    "section": "Step 4: Interpolation to vertical levels",
    "text": "Step 4: Interpolation to vertical levels\nWe use the functionvert_levs from spatial_scalesmodule to interpolate the data to same pressure levels, when we do not specify the levels, by default the interpolation is to: 1000,975,950,925,900,850,800,700,600,500,400,300,200 hPa. The dataset dd should contain the total pressure and the variables we are interested in.\ndd2=vert_levs(dd,['U','W','QE'],lvls=None)"
  },
  {
    "objectID": "es/03_tutorial_03.html#step-5-plotting-precipitation-maps",
    "href": "es/03_tutorial_03.html#step-5-plotting-precipitation-maps",
    "title": "Pressure levels variables",
    "section": "Step 5: Plotting Precipitation Maps",
    "text": "Step 5: Plotting Precipitation Maps\nNext, we’ll generate cross section plots with specific humidity contours and wind vectors using the cross_section_xz function from the map_plots module. This function takes the dataset with specific humidity, total pressure and wind components, humidity levels, exportation settings, output path, temporal scale (‘H’ for hourly, ‘D’ for daily, ‘M’ for monthly, ‘Y’ for yearly) and vector speed.\n# Example usage\nlevs=[0,0.2,0.4,0.6,0.8,1,1.5,2,2.5,5,7.5,10,12,15,18]\ncmaps=cmocean.tools.lighten(matplotlib.colormaps['rainbow'],0.90)# 1d\ndf=dd2.sel(lat=-5,method='nearest').sel(lon=slice(-90,-80),time=slice('2023-03-10','2023-03-13'))\ndf['QE']=df['QE']*1000\ncross_section_xz(df,'QE',levs,cmaps,'QE',quiverkey_speed=8, output_path=None, freq='D',\n                           save_maps=False)"
  },
  {
    "objectID": "es/03_tutorial_01.html",
    "href": "es/03_tutorial_01.html",
    "title": "Reading a Single File",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision."
  },
  {
    "objectID": "es/03_tutorial_01.html#step-1-reading-wrf-data",
    "href": "es/03_tutorial_01.html#step-1-reading-wrf-data",
    "title": "Reading a Single File",
    "section": "Step 1: Reading WRF Data",
    "text": "Step 1: Reading WRF Data\nWe begin by setting the absolute path of the output file we intend to work with and assign it to a variable, in this case, file_name.\nfile_name = '/data/datos/COW/OUT_DIAG_WRF/wrfouts/wrfout_d01_2023-03-10_03:00:00'\nSince we have the flexibility to specify which variables to exclude when reading netCDF files using the drop_variables argument (see xarray functions open_dataset and open_mfdataset), we leverage the _drop_wrf_vars function from the module in_out. This function takes the list of variables we require and generates a list containing all variables present in the output file, subsequently removing those we are not interested in (such as ‘RAINC’, ‘RAINNC’, ‘RAINSH’, ‘U10’, ‘V10’, ‘SSTSK’).\ndvars = in_out._drop_vars(file_name, ['RAINC', 'RAINNC', 'RAINSH', 'U10', 'V10', 'SSTSK'], model='wrf')\nSubsequently, we utilize the read_wrf_single function to selectively read the variables of interest. This function accepts the input path (file_name in this case), the list of variables to be excluded (vars), any required time difference (e.g., '5 hours'), and the corresponding sign of the time difference (-1 for negative, 1 for positive). The outcome is an xarray.Dataset containing longitude, latitude, time, and the specified variables. Optionally, you can designate a save path to export the netCDF.\nds = in_out.read_wrf_single(file_name, dvars, '5 hours', -1)"
  },
  {
    "objectID": "es/03_tutorial_01.html#step-2-calculating-precipitation-and-wind-speed",
    "href": "es/03_tutorial_01.html#step-2-calculating-precipitation-and-wind-speed",
    "title": "Reading a Single File",
    "section": "Step 2: Calculating Precipitation and Wind Speed",
    "text": "Step 2: Calculating Precipitation and Wind Speed\nIn this step, we will utilize the met_vars module to calculate precipitation (calc_pp), wind speed (calc_wsp), and convert sea surface temperature from Kelvin to Celsius (calc_celsius).\nThe calc_pp function has an optional argument vars_to_sum, allowing users to specify which variables to sum to obtain total precipitation. If no variables are provided, it will default to summing the three variables: RAINC, RAINNC, and RAINSH.\nds_sfc = met_vars.calc_pp(ds, vars_to_sum=['RAINC', 'RAINNC', 'RAINSH'], elim=True)\nds_sfc = met_vars.calc_wsp(ds_sfc, elim=False)\nds_sfc = met_vars.calc_celsius(ds_sfc, 'SSTSK')\nBy running these commands, we ensure that our dataset ds_sfc now contains calculated precipitation, wind speed, and sea surface temperature in Celsius, ready for further analysis or visualization."
  },
  {
    "objectID": "es/03_tutorial_01.html#step-3-plotting-precipitation-maps",
    "href": "es/03_tutorial_01.html#step-3-plotting-precipitation-maps",
    "title": "Reading a Single File",
    "section": "Step 3: Plotting Precipitation Maps",
    "text": "Step 3: Plotting Precipitation Maps\nNext, we’ll generate precipitation maps with SST contours and wind vectors using the map_pp_uv10_sst function from the map_plots module. This function takes the rainfall (PP) variable as input, followed by the dataset with SST and wind components, precipitation levels, SST contours, optional shapefile, exportation settings, output path, temporal scale (‘H’ for hourly, ‘D’ for daily, ‘M’ for monthly, ‘Y’ for yearly), vector speed, and plot extent ([x1, x2, y1, y2]).\n# Example usage\nprecipitation_levels = [1, 2, 3, 5, 7, 11, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\nsst_contour_levels = [26, 27, 28]\n\nmap_plots.map_pp_uv10_sst(ds_sfc['PP'], ds_sfc, precipitation_levels, sst_contour_levels, shapefile=None, \n                           output_path='.', save_maps=True, freq='H',\n                           quiverkey_speed=10, extent=None)"
  },
  {
    "objectID": "es/01_install.html",
    "href": "es/01_install.html",
    "title": "Installation",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision."
  },
  {
    "objectID": "es/01_install.html#required-dependencies",
    "href": "es/01_install.html#required-dependencies",
    "title": "Installation",
    "section": "Required dependencies:",
    "text": "Required dependencies:\n\nPython &gt;= 3.9\nxarray\nwrf-python\nnetCDF4\nDask"
  },
  {
    "objectID": "es/01_install.html#optional-dependencies",
    "href": "es/01_install.html#optional-dependencies",
    "title": "Installation",
    "section": "Optional dependencies:",
    "text": "Optional dependencies:\nFor optimal performance, it is highly recommended that you install the following dependencies:\n\nbottleneck\nCartopy\nIPython\nJupyterLab"
  },
  {
    "objectID": "es/01_install.html#step-by-step-instructions",
    "href": "es/01_install.html#step-by-step-instructions",
    "title": "Installation",
    "section": "Step-by-step instructions",
    "text": "Step-by-step instructions\nThese instructions should function in most operating systems, including Windows, macOS, and Linux, as Conda and Miniforge are designed to be cross-platform. However, there might be slight differences in the installation process or command syntax depending on the operating system.\nTo ensure clarity and compatibility across all operating systems, consider the following:\n\nWindows:\n\nUsers might need to open the terminal or command prompt as an administrator to execute some commands.\nPaths in the terminal should use backslashes (\\) instead of forward slashes (/).\n\nmacOS:\n\nUsers may need to install command-line developer tools if they haven’t done so already. This can be done by running xcode-select --install in the terminal.\nEnsure that users have permission to execute scripts and install packages.\n\nLinux:\n\nSome Linux distributions might require additional dependencies or configurations for Conda or Miniforge to work properly. It’s advisable to consult the documentation specific to the Linux distribution being used.\n\n\n\nUsing Conda\n\nDownload and Install Miniforge:\n\nBefore installing scahpy, you need to ensure that you have Conda installed on your system. Miniforge is a minimal distribution of Conda that includes essential tools for package management.\nGo to the Miniforge GitHub page and follow the instructions to download and install Miniforge suitable for your operating system.\n\nCreate a New Conda Environment and Install SCAHpy:\n\nOnce Conda is installed, you can create a new Conda environment specifically for scahpy and its dependencies. To do this, you’ll use an environment file called environment.yml, which contains a list of packages and their versions required for scahpy to function properly.\nDownload the environment.yml file from the SCAHpy GitHub repository.\nOpen a terminal or command prompt and navigate to the directory where the environment.yml file is located.\nRun the following command to create a new Conda environment named scahpy_env and install all the packages listed in the environment.yml file:\nconda env create --file environment.yml -n scahpy_env\nThis command will create a new Conda environment named scahpy_env and install all the required dependencies listed in the environment.yml file into this environment.\nOnce the environment is created, activate it using the following command:\nconda activate scahpy_env\n\n\nBy following these steps, you’ll have scahpy and all its dependencies installed and ready to use in your Conda environment.\n\n\nUsing Mamba\n\nDownload and Install Mamba: Before installing scahpy, you need to ensure that you have Mamba installed on your system. Mamba is a package manager for Conda environments and can be installed via Miniforge, which is a minimal distribution of Conda that includes Mamba.\n\nGo to the Miniforge GitHub page and follow the instructions to download and install Miniforge suitable for your operating system.\n\nInstall SCAHpy and Dependencies:\n\nThe easiest and recommended way to install scahpy along with its required dependencies is by using an environment file called environment.yml. This file contains a list of packages and their versions that are needed for scahpy to function properly.\nDownload the environment.yml file from the SCAHpy GitHub repository.\nOpen a terminal or command prompt and navigate to the directory where the environment.yml file is located.\nRun the following command to create a new Conda environment named scahpy_env and install all the packages listed in the environment.yml file:\nmamba env create --file environment.yml -n scahpy_env\nThis command will create a new Conda environment named scahpy_env and install all the required dependencies listed in the environment.yml file into this environment.\n\n\nBy following these steps, you’ll have scahpy and all its dependencies installed and ready to use in your Python environment.\n\n\nUsing pip\n\nFirst, ensure you have Python and pip installed on your system. You can download and install Python from the official Python website, which usually includes pip by default.\nThe easiest way to install scahpy and its dependencies is by creating a virtual environment and installing from a requirements file. Open a terminal or command prompt, then run the following commands:\n\n# Create a virtual environment (optional but recommended)\npython -m venv scahpy_env\n# Activate the virtual environment\n\n# On Windows\nscahpy_env\\Scripts\\activate\n# On macOS/Linux\nsource scahpy_env/bin/activate\n\n# Install scahpy and dependencies from requirements.txt\npip install -r requirements.txt\nIn this example, requirements.txt is a file containing a list of dependencies including scahpy. You would need to provide or generate this file yourself, listing all necessary packages and their versions: wrf-python, netCDF4, xarray, numpy, pandas, matplotlib, cartopy, geopandas, datetime, scahpy."
  },
  {
    "objectID": "en/06_references.html",
    "href": "en/06_references.html",
    "title": "References",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.\n\n\n\n\n\n\nReferences",
    "crumbs": [
      "Help & References",
      "References"
    ]
  },
  {
    "objectID": "en/04_API.html",
    "href": "en/04_API.html",
    "title": "API reference",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#in_out.read_wrf_multi",
    "href": "en/04_API.html#in_out.read_wrf_multi",
    "title": "API reference",
    "section": "in_out.read_wrf_multi",
    "text": "in_out.read_wrf_multi\nin_out.read_wrf_multi(files,list_no_vars,difHor=0,sign=1)\nRead a list of wrfout files for the variables selected.\n\nParameters:\n\nfiles : List of wrfout files\nlist_no_vars : List of variables to be delated\ndifHor : String with the hours t\nsign: -1 or 1 according to the difference\n\n\n\nReturns\n\nfig (matplotlib.figure.Figure)\nax (matplotlib.axes.Axes)",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#in_out.read_wrf_single",
    "href": "en/04_API.html#in_out.read_wrf_single",
    "title": "API reference",
    "section": "in_out.read_wrf_single",
    "text": "in_out.read_wrf_single\nin_out.ds_wrf_single(file,list_no_vars,difHor=0,sign=1)\nRead a list of wrfout files for the variables selected.\n\nParameters:\n\nfile : List of wrfout files\nlist_no_vars : List of variables to be delated\ndifHor : String with the hours t\nsign: -1 or 1 according to the difference\n\n\n\nReturns\n\nfig (matplotlib.figure.Figure)\nax (matplotlib.axes.Axes)",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#in_out.extract_station_wrf",
    "href": "en/04_API.html#in_out.extract_station_wrf",
    "title": "API reference",
    "section": "in_out.extract_station_wrf",
    "text": "in_out.extract_station_wrf\nin_out.extract_station_wrf(out,station,lon_col, lat_col, name_col, output_format='netcdf')\nExtracts data from a WRF output file using station coordinates provided in a CSV or shapefile.\n\nParameters:\n\nout (nc): the wrf outfile already laoded.\nstation (str): Path to the CSV or shapefile containing station coordinates.\nlon_col (str): Name of the column containing longitude values.\nlat_col (str): Name of the column containing latitude values.\nname_col (str): Name of the column containing station names.\noutput_format (str, optional): Output format (‘netcdf’ or ‘dataframe’). Defaults to ‘netcdf’.\n\n\n\nReturns\n\nfig (matplotlib.figure.Figure)\nax (matplotlib.axes.Axes)",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#met_vars.calc_pp",
    "href": "en/04_API.html#met_vars.calc_pp",
    "title": "API reference",
    "section": "met_vars.calc_pp",
    "text": "met_vars.calc_pp\nmet_diag.calc_pp(ds, elim=False)\nde-acumulate the rainfall and save it as PP.\n\nParameters:\n\nds (nc): dataset with the variables RAINC, RAINNC and RAINSH already loaded.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#met_vars.calc_wsp",
    "href": "en/04_API.html#met_vars.calc_wsp",
    "title": "API reference",
    "section": "met_vars.calc_wsp",
    "text": "met_vars.calc_wsp\nmet_diag.calc_wsp(ds, elim=False)\ncalculate the wind speed.\n\nParameters:\n\nds (nc): dataset with the variables U10 and V10 already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#met_vars.calc_pres",
    "href": "en/04_API.html#met_vars.calc_pres",
    "title": "API reference",
    "section": "met_vars.calc_pres",
    "text": "met_vars.calc_pres\nmet_diag.calc_pres(ds, elim=False)\ncalculate the total atmospheric pressure and save it as Presion.\n\nParameters:\n\nds (nc): dataset with the variables P, PB already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#met_vars.calc_tp",
    "href": "en/04_API.html#met_vars.calc_tp",
    "title": "API reference",
    "section": "met_vars.calc_tp",
    "text": "met_vars.calc_tp\nmet_diag.calc_tp(ds, elim=False)\ncalculate the potential temperature and save it as TPo.\n\nParameters:\n\nds (nc): dataset with the variable T already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#met_vars.calc_qe",
    "href": "en/04_API.html#met_vars.calc_qe",
    "title": "API reference",
    "section": "met_vars.calc_qe",
    "text": "met_vars.calc_qe\nmet_diag.calc_qe(ds, elim=False)\ncalculate the specific humidity and save it as QE.\n\nParameters:\n\nds (nc): dataset with the variable QVAPOR already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#spatial_scales.vert_levs",
    "href": "en/04_API.html#spatial_scales.vert_levs",
    "title": "API reference",
    "section": "spatial_scales.vert_levs",
    "text": "spatial_scales.vert_levs\nspatial_scales.vert_levs(ds,varis,lvls=None):\nInterpolate vertical levels to a pressure variable\n\nParameters:\n\nds (nc): dataset already loaded.\nvaris (list): list of vertical variables to interpolate.\nlvls (list): list of levels to be interpolated, if none provided, it will use [1000,975,950,925,900,850,800,700,600,500,400,300,200] as default.\n\n\n\nReturns\n\nnetcdf xarray.Dataset",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#temp_scales.dmy_var",
    "href": "en/04_API.html#temp_scales.dmy_var",
    "title": "API reference",
    "section": "temp_scales.dmy_var",
    "text": "temp_scales.dmy_var\ntemp_scales.dmy_var(ds,tiempo=None ,accum=None, avg=None, mediana=None):\nConvert hourly (default wrf out) time to any acceptable by resample function.\n\nParameters:\n\nds : Dataset loaded\ntiempo : Time accepted by resample\naccum : List of variables who need sum\navg : if True use the mean function\nmediana : if True use the median function\n\n\n\nReturns\n\nnetcdf xarray.Dataset",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#temp_scales.monthly_clim",
    "href": "en/04_API.html#temp_scales.monthly_clim",
    "title": "API reference",
    "section": "temp_scales.monthly_clim",
    "text": "temp_scales.monthly_clim\ntemp_scales.monthly_clim(ds, stat=None, time_slice=None):\nConvert a Dataset to monthly climatology.\n\nParameters:\n\nds : Dataset loaded\nstat : Mean or median\ntime_slice : use the slice(ini,fin)\n\n\n\nReturns\n\nnetcdf xarray.Dataset",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/04_API.html#temp_scales.daily_clim",
    "href": "en/04_API.html#temp_scales.daily_clim",
    "title": "API reference",
    "section": "temp_scales.daily_clim",
    "text": "temp_scales.daily_clim\ntemp_scales.daily_clim(ds, var):\nGenerate daily climatology using moving window (mw) each 15 days.\n\nParameters:\n\nds : Dataset loaded\nvar : str with the variable’s name\n\n\n\nReturns\n\nnetcdf xarray.Dataset",
    "crumbs": [
      "Help & References",
      "API Reference"
    ]
  },
  {
    "objectID": "en/03_tutorial_02.html",
    "href": "en/03_tutorial_02.html",
    "title": "Reading Multiple File",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.",
    "crumbs": [
      "Tutorials",
      "Tutorial 2: Reading CROCO"
    ]
  },
  {
    "objectID": "en/03_tutorial_02.html#step-1-reading-wrf-data",
    "href": "en/03_tutorial_02.html#step-1-reading-wrf-data",
    "title": "Reading Multiple File",
    "section": "Step 1: Reading WRF Data",
    "text": "Step 1: Reading WRF Data\nWe initiate the process by listing all the files we want to read using the glob package and assigning them to the variable list_files.\nlist_files = sorted(glob.glob('/data/datos/COW/OUT_DIAG_WRF/wrfouts/wrfout_d01_*'))\nGiven the capability to specify excluded variables when reading netCDF files using the drop_variables argument (refer to xarray functions open_dataset and open_mfdataset), we utilize the _drop_vars function from the module in_out. This function takes the list of variables we require and generates a list containing all variables present in the output file, subsequently removing those we are not interested in (such as ‘RAINC’, ‘RAINNC’, ‘RAINSH’, ‘U10’, ‘V10’, ‘SSTSK’). For this purpose, we use the first file from our list of files, assigning it to the variable dvars.\ndvars = in_out._drop_vars(list_files[0], ['RAINC', 'RAINNC', 'RAINSH', 'U10', 'V10', 'SSTSK'], model='wrf')\nSubsequently, we utilize the read_wrf_multi function to selectively read the variables of interest. This function accepts the input path (file_name in this case), the list of variables to be excluded (vars), any required time difference (e.g., '5 hours'), and the corresponding sign of the time difference (-1 for negative, 1 for positive). The outcome is an xarray.Dataset containing longitude, latitude, time, and the specified variables. Optionally, you can designate a save path to export the netCDF.\nds = in_out.read_wrf_multi(list_files, dvars, '5 hours', -1)",
    "crumbs": [
      "Tutorials",
      "Tutorial 2: Reading CROCO"
    ]
  },
  {
    "objectID": "en/03_tutorial_02.html#step-2-calculating-precipitation-and-wind-speed",
    "href": "en/03_tutorial_02.html#step-2-calculating-precipitation-and-wind-speed",
    "title": "Reading Multiple File",
    "section": "Step 2: Calculating Precipitation and Wind Speed",
    "text": "Step 2: Calculating Precipitation and Wind Speed\nIn this step, we will utilize the met_vars module to calculate precipitation (calc_pp), wind speed (calc_wsp), and convert sea surface temperature from Kelvin to Celsius (calc_celsius).\nThe calc_pp function has an optional argument vars_to_sum, allowing users to specify which variables to sum to obtain total precipitation. If no variables are provided, it will default to summing the three variables: RAINC, RAINNC, and RAINSH.\nds_sfc = met_vars.calc_pp(ds, vars_to_sum=['RAINC', 'RAINNC', 'RAINSH'], elim=True)\nds_sfc = met_vars.calc_wsp(ds_sfc, elim=False)\nds_sfc = met_vars.calc_celsius(ds_sfc, 'SSTSK')\nBy running these commands, we ensure that our dataset ds_sfc now contains calculated precipitation, wind speed, and sea surface temperature in Celsius, ready for further analysis or visualization.",
    "crumbs": [
      "Tutorials",
      "Tutorial 2: Reading CROCO"
    ]
  },
  {
    "objectID": "en/03_tutorial_02.html#step-3-aggregating-the-data",
    "href": "en/03_tutorial_02.html#step-3-aggregating-the-data",
    "title": "Reading Multiple File",
    "section": "Step 3: Aggregating the Data",
    "text": "Step 3: Aggregating the Data\nNow, we’ll aggregate the data to operate on a daily time scale instead of hourly. To achieve this, we’ll utilize the dmy_var function from the temp_scales module. This function takes an xarray.Dataset as input, where we specify the desired time scale (e.g., ‘1D’ for daily, ‘ME’ for monthly, ‘YE’ for yearly). Additionally, we can specify which variables should be aggregated by sum, average, or median by providing lists for each aggregation method.\ndd = temp_scales.dmy_var(ds_sfc, tiempo='1D', accum=['PP'], avg=['U10', 'V10'], mediana=['SSTSK'])\nBy executing this code, we’ll have our data aggregated to a daily time scale, with certain variables summed, averaged, or median-calculated according to our specifications.",
    "crumbs": [
      "Tutorials",
      "Tutorial 2: Reading CROCO"
    ]
  },
  {
    "objectID": "en/03_tutorial_02.html#step-4-plotting-precipitation-maps",
    "href": "en/03_tutorial_02.html#step-4-plotting-precipitation-maps",
    "title": "Reading Multiple File",
    "section": "Step 4: Plotting Precipitation Maps",
    "text": "Step 4: Plotting Precipitation Maps\nNext, we’ll generate precipitation maps with SST contours and wind vectors using the map_pp_uv10_sst function from the map_plots module. This function takes the rainfall (PP) variable as input, followed by the dataset with SST and wind components, precipitation levels, SST contours, optional shapefile, exportation settings, output path, temporal scale (‘H’ for hourly, ‘D’ for daily, ‘M’ for monthly, ‘Y’ for yearly), vector speed, and plot extent ([x1, x2, y1, y2]).\n# Example usage\nprecipitation_levels = [1, 2, 3, 5, 7, 11, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\nsst_contour_levels = [26, 27, 28]\n\nmap_plots.map_pp_uv10_sst(ds_sfc['PP'], ds_sfc, precipitation_levels, sst_contour_levels, shapefile=None, \n                           output_path='.', save_maps=True, freq='H',\n                           quiverkey_speed=10, extent=None)",
    "crumbs": [
      "Tutorials",
      "Tutorial 2: Reading CROCO"
    ]
  },
  {
    "objectID": "en/02_use.html",
    "href": "en/02_use.html",
    "title": "Usage",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.\nAn overview of scahpy capabilities will be displayed.",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "en/02_use.html#importing-the-package",
    "href": "en/02_use.html#importing-the-package",
    "title": "Usage",
    "section": "Importing the Package",
    "text": "Importing the Package\nTo import all the modules in scahpy we can use the * cd as for example:\n\nfrom scahpy import *\n\nTo import specific modules from the package, we can specify their names:\n\nfrom scahpy import in_out, met_vars",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "en/02_use.html#reading-wrf-outputs-files",
    "href": "en/02_use.html#reading-wrf-outputs-files",
    "title": "Usage",
    "section": "Reading WRF outputs files",
    "text": "Reading WRF outputs files\nThe WRF model can generate outputs either with one time per file or multiple times in a single file. scahpy is capable of handling both scenarios. For reading multiple wrfout files, you can utilize the read_wrf_multi function, while for reading a single file, you can use the read_wrf_single function.\n\n# Example: Reading and processing multiple WRF datasets\nsfc = in_out._drop_vars('/datos/wrfout_d01_2024-01-01_03:00:00',['RAINC', 'RAINNC', 'RAINSH', 'U10', 'V10', 'SSTSK'], model='wrf')\nfiles = sorted(glob.glob('/datos/wrfout_d01*'))\nds = in_out.read_wrf_multi(files, sfc, '5 hours', -1)",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "en/02_use.html#calculating-precipitation",
    "href": "en/02_use.html#calculating-precipitation",
    "title": "Usage",
    "section": "Calculating Precipitation",
    "text": "Calculating Precipitation\nscahpy has a module called met_vars designed specifically for calculating various diagnostic variables, such as precipitation, using the calc_pp function.\n\n# Example: Calculating precipitation using diagnostics module\nds2 = met_vars.calc_pp(ds,vars_to_sum=['RAINC', 'RAINNC', 'RAINSH'],True)",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "en/01_install.html",
    "href": "en/01_install.html",
    "title": "Installation",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "en/01_install.html#required-dependencies",
    "href": "en/01_install.html#required-dependencies",
    "title": "Installation",
    "section": "Required dependencies:",
    "text": "Required dependencies:\n\nPython &gt;= 3.9\nxarray\nwrf-python\nnetCDF4\nDask",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "en/01_install.html#optional-dependencies",
    "href": "en/01_install.html#optional-dependencies",
    "title": "Installation",
    "section": "Optional dependencies:",
    "text": "Optional dependencies:\nFor optimal performance, it is highly recommended that you install the following dependencies:\n\nbottleneck\nCartopy\nIPython\nJupyterLab",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "en/01_install.html#step-by-step-instructions",
    "href": "en/01_install.html#step-by-step-instructions",
    "title": "Installation",
    "section": "Step-by-step instructions",
    "text": "Step-by-step instructions\nThese instructions should function in most operating systems, including Windows, macOS, and Linux, as Conda and Miniforge are designed to be cross-platform. However, there might be slight differences in the installation process or command syntax depending on the operating system.\nTo ensure clarity and compatibility across all operating systems, consider the following:\n\nWindows:\n\nUsers might need to open the terminal or command prompt as an administrator to execute some commands.\nPaths in the terminal should use backslashes (\\) instead of forward slashes (/).\n\nmacOS:\n\nUsers may need to install command-line developer tools if they haven’t done so already. This can be done by running xcode-select --install in the terminal.\nEnsure that users have permission to execute scripts and install packages.\n\nLinux:\n\nSome Linux distributions might require additional dependencies or configurations for Conda or Miniforge to work properly. It’s advisable to consult the documentation specific to the Linux distribution being used.\n\n\n\nUsing Conda\n\nDownload and Install Miniforge:\n\nBefore installing scahpy, you need to ensure that you have Conda installed on your system. Miniforge is a minimal distribution of Conda that includes essential tools for package management.\nGo to the Miniforge GitHub page and follow the instructions to download and install Miniforge suitable for your operating system.\n\nCreate a New Conda Environment and Install SCAHpy:\n\nOnce Conda is installed, you can create a new Conda environment specifically for scahpy and its dependencies. To do this, you’ll use an environment file called environment.yml, which contains a list of packages and their versions required for scahpy to function properly.\nDownload the environment.yml file from the SCAHpy GitHub repository.\nOpen a terminal or command prompt and navigate to the directory where the environment.yml file is located.\nRun the following command to create a new Conda environment named scahpy_env and install all the packages listed in the environment.yml file:\nconda env create --file environment.yml -n scahpy_env\nThis command will create a new Conda environment named scahpy_env and install all the required dependencies listed in the environment.yml file into this environment.\nOnce the environment is created, activate it using the following command:\nconda activate scahpy_env\n\n\nBy following these steps, you’ll have scahpy and all its dependencies installed and ready to use in your Conda environment.\n\n\nUsing Mamba\n\nDownload and Install Mamba: Before installing scahpy, you need to ensure that you have Mamba installed on your system. Mamba is a package manager for Conda environments and can be installed via Miniforge, which is a minimal distribution of Conda that includes Mamba.\n\nGo to the Miniforge GitHub page and follow the instructions to download and install Miniforge suitable for your operating system.\n\nInstall SCAHpy and Dependencies:\n\nThe easiest and recommended way to install scahpy along with its required dependencies is by using an environment file called environment.yml. This file contains a list of packages and their versions that are needed for scahpy to function properly.\nDownload the environment.yml file from the SCAHpy GitHub repository.\nOpen a terminal or command prompt and navigate to the directory where the environment.yml file is located.\nRun the following command to create a new Conda environment named scahpy_env and install all the packages listed in the environment.yml file:\nmamba env create --file environment.yml -n scahpy_env\nThis command will create a new Conda environment named scahpy_env and install all the required dependencies listed in the environment.yml file into this environment.\n\n\nBy following these steps, you’ll have scahpy and all its dependencies installed and ready to use in your Python environment.\n\n\nUsing pip\n\nFirst, ensure you have Python and pip installed on your system. You can download and install Python from the official Python website, which usually includes pip by default.\nThe easiest way to install scahpy and its dependencies is by creating a virtual environment and installing from a requirements file. Open a terminal or command prompt, then run the following commands:\n\n# Create a virtual environment (optional but recommended)\npython -m venv scahpy_env\n# Activate the virtual environment\n\n# On Windows\nscahpy_env\\Scripts\\activate\n# On macOS/Linux\nsource scahpy_env/bin/activate\n\n# Install scahpy and dependencies from requirements.txt\npip install -r requirements.txt\nIn this example, requirements.txt is a file containing a list of dependencies including scahpy. You would need to provide or generate this file yourself, listing all necessary packages and their versions: wrf-python, netCDF4, xarray, numpy, pandas, matplotlib, cartopy, geopandas, datetime, scahpy.",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "en/03_tutorial_01.html",
    "href": "en/03_tutorial_01.html",
    "title": "Reading a Single File",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.",
    "crumbs": [
      "Tutorials",
      "Tutorial 1: Reading WRF"
    ]
  },
  {
    "objectID": "en/03_tutorial_01.html#step-1-reading-wrf-data",
    "href": "en/03_tutorial_01.html#step-1-reading-wrf-data",
    "title": "Reading a Single File",
    "section": "Step 1: Reading WRF Data",
    "text": "Step 1: Reading WRF Data\nWe begin by setting the absolute path of the output file we intend to work with and assign it to a variable, in this case, file_name.\nfile_name = '/data/datos/COW/OUT_DIAG_WRF/wrfouts/wrfout_d01_2023-03-10_03:00:00'\nSince we have the flexibility to specify which variables to exclude when reading netCDF files using the drop_variables argument (see xarray functions open_dataset and open_mfdataset), we leverage the _drop_wrf_vars function from the module in_out. This function takes the list of variables we require and generates a list containing all variables present in the output file, subsequently removing those we are not interested in (such as ‘RAINC’, ‘RAINNC’, ‘RAINSH’, ‘U10’, ‘V10’, ‘SSTSK’).\ndvars = in_out._drop_vars(file_name, ['RAINC', 'RAINNC', 'RAINSH', 'U10', 'V10', 'SSTSK'], model='wrf')\nSubsequently, we utilize the read_wrf_single function to selectively read the variables of interest. This function accepts the input path (file_name in this case), the list of variables to be excluded (vars), any required time difference (e.g., '5 hours'), and the corresponding sign of the time difference (-1 for negative, 1 for positive). The outcome is an xarray.Dataset containing longitude, latitude, time, and the specified variables. Optionally, you can designate a save path to export the netCDF.\nds = in_out.read_wrf_single(file_name, dvars, '5 hours', -1)",
    "crumbs": [
      "Tutorials",
      "Tutorial 1: Reading WRF"
    ]
  },
  {
    "objectID": "en/03_tutorial_01.html#step-2-calculating-precipitation-and-wind-speed",
    "href": "en/03_tutorial_01.html#step-2-calculating-precipitation-and-wind-speed",
    "title": "Reading a Single File",
    "section": "Step 2: Calculating Precipitation and Wind Speed",
    "text": "Step 2: Calculating Precipitation and Wind Speed\nIn this step, we will utilize the met_vars module to calculate precipitation (calc_pp), wind speed (calc_wsp), and convert sea surface temperature from Kelvin to Celsius (calc_celsius).\nThe calc_pp function has an optional argument vars_to_sum, allowing users to specify which variables to sum to obtain total precipitation. If no variables are provided, it will default to summing the three variables: RAINC, RAINNC, and RAINSH.\nds_sfc = met_vars.calc_pp(ds, vars_to_sum=['RAINC', 'RAINNC', 'RAINSH'], elim=True)\nds_sfc = met_vars.calc_wsp(ds_sfc, elim=False)\nds_sfc = met_vars.calc_celsius(ds_sfc, 'SSTSK')\nBy running these commands, we ensure that our dataset ds_sfc now contains calculated precipitation, wind speed, and sea surface temperature in Celsius, ready for further analysis or visualization.",
    "crumbs": [
      "Tutorials",
      "Tutorial 1: Reading WRF"
    ]
  },
  {
    "objectID": "en/03_tutorial_01.html#step-3-plotting-precipitation-maps",
    "href": "en/03_tutorial_01.html#step-3-plotting-precipitation-maps",
    "title": "Reading a Single File",
    "section": "Step 3: Plotting Precipitation Maps",
    "text": "Step 3: Plotting Precipitation Maps\nNext, we’ll generate precipitation maps with SST contours and wind vectors using the map_pp_uv10_sst function from the map_plots module. This function takes the rainfall (PP) variable as input, followed by the dataset with SST and wind components, precipitation levels, SST contours, optional shapefile, exportation settings, output path, temporal scale (‘H’ for hourly, ‘D’ for daily, ‘M’ for monthly, ‘Y’ for yearly), vector speed, and plot extent ([x1, x2, y1, y2]).\n# Example usage\nprecipitation_levels = [1, 2, 3, 5, 7, 11, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\nsst_contour_levels = [26, 27, 28]\n\nmap_plots.map_pp_uv10_sst(ds_sfc['PP'], ds_sfc, precipitation_levels, sst_contour_levels, shapefile=None, \n                           output_path='.', save_maps=True, freq='H',\n                           quiverkey_speed=10, extent=None)",
    "crumbs": [
      "Tutorials",
      "Tutorial 1: Reading WRF"
    ]
  },
  {
    "objectID": "en/03_tutorial_03.html",
    "href": "en/03_tutorial_03.html",
    "title": "Pressure levels variables",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.",
    "crumbs": [
      "Tutorials",
      "Tutorial 3: Basic Plots"
    ]
  },
  {
    "objectID": "en/03_tutorial_03.html#step-1-reading-wrf-data",
    "href": "en/03_tutorial_03.html#step-1-reading-wrf-data",
    "title": "Pressure levels variables",
    "section": "Step 1: Reading WRF Data",
    "text": "Step 1: Reading WRF Data\nWe initiate the process by listing all the files we want to read using the glob package and assigning them to the variable list_files.\nlist_files = sorted(glob.glob('/data/datos/COW/OUT_DIAG_WRF/wrfouts/wrfout_d01_*'))\nGiven the capability to specify excluded variables when reading netCDF files using the drop_variables argument (refer to xarray functions open_dataset and open_mfdataset), we utilize the _drop_vars function from the module in_out. This function takes the list of variables we require and generates a list containing all variables present in the output file, subsequently removing those we are not interested in (such as ‘P’, ‘PB’, ‘U’, ‘W’, ‘QVAPOR’). For this purpose, we use the first file from our list of files, assigning it to the variable dvars.\ndvars = in_out._drop_vars(list_files[0], ['P', 'PB', 'U', 'W', 'QVAPOR'], model='wrf')\nSubsequently, we utilize the read_wrf_multi function to selectively read the variables of interest. This function accepts the input path (file_name in this case), the list of variables to be excluded (dvars), any required time difference (e.g., '5 hours'), and the corresponding sign of the time difference (-1 for negative, 1 for positive). The outcome is an xarray.Dataset containing longitude, latitude, bottom_top, time, and the specified variables. Optionally, you can designate a save path to export the netCDF.\nds = in_out.read_wrf_multi(list_files, dvars, '5 hours', -1)",
    "crumbs": [
      "Tutorials",
      "Tutorial 3: Basic Plots"
    ]
  },
  {
    "objectID": "en/03_tutorial_03.html#step-2-calculating-specific-humidity-and-total-pressure",
    "href": "en/03_tutorial_03.html#step-2-calculating-specific-humidity-and-total-pressure",
    "title": "Pressure levels variables",
    "section": "Step 2: Calculating Specific Humidity and Total pressure",
    "text": "Step 2: Calculating Specific Humidity and Total pressure\nIn this step, we will utilize the met_diag module to calculate specific humidity (calc_qe), and total pressure (calc_pres). Whe have the option of the parameter elimthat can be set to True or False in order to remove some variables used to calculate the final variable.\nds_lvl = met_vars.calc_qe(ds, elim=True)\nds_lvl = met_vars.calc_pres(ds_lvl, elim=True)\nBy running these commands, we ensure that our dataset ds_lvl now contains calculated specific humidity and total pressure, ready for further analysis or visualization.",
    "crumbs": [
      "Tutorials",
      "Tutorial 3: Basic Plots"
    ]
  },
  {
    "objectID": "en/03_tutorial_03.html#step-3-aggregating-the-data",
    "href": "en/03_tutorial_03.html#step-3-aggregating-the-data",
    "title": "Pressure levels variables",
    "section": "Step 3: Aggregating the Data",
    "text": "Step 3: Aggregating the Data\nNow, we’ll aggregate the data to operate on a daily time scale instead of hourly. To achieve this, we’ll utilize the dmy_var function from the temp_scales module. This function takes an xarray.Dataset as input, where we specify the desired time scale (e.g., ‘1D’ for daily, ‘ME’ for monthly, ‘YE’ for yearly). Additionally, we can specify which variables should be aggregated by sum, average, or median by providing lists for each aggregation method.\ndd = temp_scales.dmy_var(ds_lvl, tiempo='1D', accum=None, avg=['Presion','U','W','QE'], mediana=None)\nBy executing this code, we’ll have our data aggregated to a daily time scale, with variables averaged according to our specifications.",
    "crumbs": [
      "Tutorials",
      "Tutorial 3: Basic Plots"
    ]
  },
  {
    "objectID": "en/03_tutorial_03.html#step-4-interpolation-to-vertical-levels",
    "href": "en/03_tutorial_03.html#step-4-interpolation-to-vertical-levels",
    "title": "Pressure levels variables",
    "section": "Step 4: Interpolation to vertical levels",
    "text": "Step 4: Interpolation to vertical levels\nWe use the functionvert_levs from spatial_scalesmodule to interpolate the data to same pressure levels, when we do not specify the levels, by default the interpolation is to: 1000,975,950,925,900,850,800,700,600,500,400,300,200 hPa. The dataset dd should contain the total pressure and the variables we are interested in.\ndd2=vert_levs(dd,['U','W','QE'],lvls=None)",
    "crumbs": [
      "Tutorials",
      "Tutorial 3: Basic Plots"
    ]
  },
  {
    "objectID": "en/03_tutorial_03.html#step-5-plotting-precipitation-maps",
    "href": "en/03_tutorial_03.html#step-5-plotting-precipitation-maps",
    "title": "Pressure levels variables",
    "section": "Step 5: Plotting Precipitation Maps",
    "text": "Step 5: Plotting Precipitation Maps\nNext, we’ll generate cross section plots with specific humidity contours and wind vectors using the cross_section_xz function from the map_plots module. This function takes the dataset with specific humidity, total pressure and wind components, humidity levels, exportation settings, output path, temporal scale (‘H’ for hourly, ‘D’ for daily, ‘M’ for monthly, ‘Y’ for yearly) and vector speed.\n# Example usage\nlevs=[0,0.2,0.4,0.6,0.8,1,1.5,2,2.5,5,7.5,10,12,15,18]\ncmaps=cmocean.tools.lighten(matplotlib.colormaps['rainbow'],0.90)# 1d\ndf=dd2.sel(lat=-5,method='nearest').sel(lon=slice(-90,-80),time=slice('2023-03-10','2023-03-13'))\ndf['QE']=df['QE']*1000\ncross_section_xz(df,'QE',levs,cmaps,'QE',quiverkey_speed=8, output_path=None, freq='D',\n                           save_maps=False)",
    "crumbs": [
      "Tutorials",
      "Tutorial 3: Basic Plots"
    ]
  },
  {
    "objectID": "en/05_contrib.html",
    "href": "en/05_contrib.html",
    "title": "Contributing",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.\n\n\n\n\n\n\nContributing\nAll types of crontributions, bugs, feedbacks are welcome!\nReport bugs and submit feedback at Github Issues.",
    "crumbs": [
      "Help & References",
      "Contributing"
    ]
  },
  {
    "objectID": "en/index.html",
    "href": "en/index.html",
    "title": "Getting Started",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "en/index.html#what-is-scahpy",
    "href": "en/index.html#what-is-scahpy",
    "title": "Getting Started",
    "section": "What is SCAHpy?",
    "text": "What is SCAHpy?\nSCAHpy is an open-source Python package developed as a post-processing tool for the atmospheric, oceanic, and hydrological components of the regional Earth System Model covering the Peruvian territory and the Pacific Ocean. This model, named IGP-RESM-COW v1, was implemented by the Geophysical Institute of Peru (IGP) under the basis of the atmospheric WRF model, the oceanic CROCO model and the coupler OASIS.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "en/index.html#why-is-scahpy",
    "href": "en/index.html#why-is-scahpy",
    "title": "Getting Started",
    "section": "Why is SCAHpy?",
    "text": "Why is SCAHpy?\nThe Python package SCAHpy was created to address the significant challenge posed by the processing of data generated by the IGP-RESM-COW model. This model, with its atmospheric component based on the WRF model, produces massive amounts of data during simulations, which require considerable time for post-processing. SCAHpy streamlines this process by homogenizing coordinates and dimensions, ensuring compatibility and facilitating data analysis. By simplifying data handling and preparation.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "en/index.html#how-to-use-scahpy",
    "href": "en/index.html#how-to-use-scahpy",
    "title": "Getting Started",
    "section": "How to use SCAHpy?",
    "text": "How to use SCAHpy?\nSCAHpy can be used as a standalone package, to get more details go to Usage and tutorials.\n\n\n\n\n\n\nNote\n\n\n\nSCAHpy has been developed and tested using IGP-RESM-COWv1 model outputs. However, it is designed to work with any WRF outputs. We are open to contributions from users!\n\n\n\nGetting Started\n\nInstallation\nUsage\n\n\n\nTutorials\n\nTutorial: Reading Single Files\nTutorial: Reading Multiple Files\nTutorial: Pressure Levels Variables\n\n\n\nHelp & Reference\n\nAPI References\nContributing",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "es/02_use.html",
    "href": "es/02_use.html",
    "title": "Usage",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.\nAn overview of scahpy capabilities will be displayed."
  },
  {
    "objectID": "es/02_use.html#importing-the-package",
    "href": "es/02_use.html#importing-the-package",
    "title": "Usage",
    "section": "Importing the Package",
    "text": "Importing the Package\nTo import all the modules in scahpy we can use the * cd as for example:\n\nfrom scahpy import *\n\nTo import specific modules from the package, we can specify their names:\n\nfrom scahpy import in_out, met_vars"
  },
  {
    "objectID": "es/02_use.html#reading-wrf-outputs-files",
    "href": "es/02_use.html#reading-wrf-outputs-files",
    "title": "Usage",
    "section": "Reading WRF outputs files",
    "text": "Reading WRF outputs files\nThe WRF model can generate outputs either with one time per file or multiple times in a single file. scahpy is capable of handling both scenarios. For reading multiple wrfout files, you can utilize the read_wrf_multi function, while for reading a single file, you can use the read_wrf_single function.\n\n# Example: Reading and processing multiple WRF datasets\nsfc = in_out._drop_vars('/datos/wrfout_d01_2024-01-01_03:00:00',['RAINC', 'RAINNC', 'RAINSH', 'U10', 'V10', 'SSTSK'], model='wrf')\nfiles = sorted(glob.glob('/datos/wrfout_d01*'))\nds = in_out.read_wrf_multi(files, sfc, '5 hours', -1)"
  },
  {
    "objectID": "es/02_use.html#calculating-precipitation",
    "href": "es/02_use.html#calculating-precipitation",
    "title": "Usage",
    "section": "Calculating Precipitation",
    "text": "Calculating Precipitation\nscahpy has a module called met_vars designed specifically for calculating various diagnostic variables, such as precipitation, using the calc_pp function.\n\n# Example: Calculating precipitation using diagnostics module\nds2 = met_vars.calc_pp(ds,vars_to_sum=['RAINC', 'RAINNC', 'RAINSH'],True)"
  },
  {
    "objectID": "es/03_tutorial_02.html",
    "href": "es/03_tutorial_02.html",
    "title": "Reading Multiple File",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision."
  },
  {
    "objectID": "es/03_tutorial_02.html#step-1-reading-wrf-data",
    "href": "es/03_tutorial_02.html#step-1-reading-wrf-data",
    "title": "Reading Multiple File",
    "section": "Step 1: Reading WRF Data",
    "text": "Step 1: Reading WRF Data\nWe initiate the process by listing all the files we want to read using the glob package and assigning them to the variable list_files.\nlist_files = sorted(glob.glob('/data/datos/COW/OUT_DIAG_WRF/wrfouts/wrfout_d01_*'))\nGiven the capability to specify excluded variables when reading netCDF files using the drop_variables argument (refer to xarray functions open_dataset and open_mfdataset), we utilize the _drop_vars function from the module in_out. This function takes the list of variables we require and generates a list containing all variables present in the output file, subsequently removing those we are not interested in (such as ‘RAINC’, ‘RAINNC’, ‘RAINSH’, ‘U10’, ‘V10’, ‘SSTSK’). For this purpose, we use the first file from our list of files, assigning it to the variable dvars.\ndvars = in_out._drop_vars(list_files[0], ['RAINC', 'RAINNC', 'RAINSH', 'U10', 'V10', 'SSTSK'], model='wrf')\nSubsequently, we utilize the read_wrf_multi function to selectively read the variables of interest. This function accepts the input path (file_name in this case), the list of variables to be excluded (vars), any required time difference (e.g., '5 hours'), and the corresponding sign of the time difference (-1 for negative, 1 for positive). The outcome is an xarray.Dataset containing longitude, latitude, time, and the specified variables. Optionally, you can designate a save path to export the netCDF.\nds = in_out.read_wrf_multi(list_files, dvars, '5 hours', -1)"
  },
  {
    "objectID": "es/03_tutorial_02.html#step-2-calculating-precipitation-and-wind-speed",
    "href": "es/03_tutorial_02.html#step-2-calculating-precipitation-and-wind-speed",
    "title": "Reading Multiple File",
    "section": "Step 2: Calculating Precipitation and Wind Speed",
    "text": "Step 2: Calculating Precipitation and Wind Speed\nIn this step, we will utilize the met_vars module to calculate precipitation (calc_pp), wind speed (calc_wsp), and convert sea surface temperature from Kelvin to Celsius (calc_celsius).\nThe calc_pp function has an optional argument vars_to_sum, allowing users to specify which variables to sum to obtain total precipitation. If no variables are provided, it will default to summing the three variables: RAINC, RAINNC, and RAINSH.\nds_sfc = met_vars.calc_pp(ds, vars_to_sum=['RAINC', 'RAINNC', 'RAINSH'], elim=True)\nds_sfc = met_vars.calc_wsp(ds_sfc, elim=False)\nds_sfc = met_vars.calc_celsius(ds_sfc, 'SSTSK')\nBy running these commands, we ensure that our dataset ds_sfc now contains calculated precipitation, wind speed, and sea surface temperature in Celsius, ready for further analysis or visualization."
  },
  {
    "objectID": "es/03_tutorial_02.html#step-3-aggregating-the-data",
    "href": "es/03_tutorial_02.html#step-3-aggregating-the-data",
    "title": "Reading Multiple File",
    "section": "Step 3: Aggregating the Data",
    "text": "Step 3: Aggregating the Data\nNow, we’ll aggregate the data to operate on a daily time scale instead of hourly. To achieve this, we’ll utilize the dmy_var function from the temp_scales module. This function takes an xarray.Dataset as input, where we specify the desired time scale (e.g., ‘1D’ for daily, ‘ME’ for monthly, ‘YE’ for yearly). Additionally, we can specify which variables should be aggregated by sum, average, or median by providing lists for each aggregation method.\ndd = temp_scales.dmy_var(ds_sfc, tiempo='1D', accum=['PP'], avg=['U10', 'V10'], mediana=['SSTSK'])\nBy executing this code, we’ll have our data aggregated to a daily time scale, with certain variables summed, averaged, or median-calculated according to our specifications."
  },
  {
    "objectID": "es/03_tutorial_02.html#step-4-plotting-precipitation-maps",
    "href": "es/03_tutorial_02.html#step-4-plotting-precipitation-maps",
    "title": "Reading Multiple File",
    "section": "Step 4: Plotting Precipitation Maps",
    "text": "Step 4: Plotting Precipitation Maps\nNext, we’ll generate precipitation maps with SST contours and wind vectors using the map_pp_uv10_sst function from the map_plots module. This function takes the rainfall (PP) variable as input, followed by the dataset with SST and wind components, precipitation levels, SST contours, optional shapefile, exportation settings, output path, temporal scale (‘H’ for hourly, ‘D’ for daily, ‘M’ for monthly, ‘Y’ for yearly), vector speed, and plot extent ([x1, x2, y1, y2]).\n# Example usage\nprecipitation_levels = [1, 2, 3, 5, 7, 11, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\nsst_contour_levels = [26, 27, 28]\n\nmap_plots.map_pp_uv10_sst(ds_sfc['PP'], ds_sfc, precipitation_levels, sst_contour_levels, shapefile=None, \n                           output_path='.', save_maps=True, freq='H',\n                           quiverkey_speed=10, extent=None)"
  },
  {
    "objectID": "es/04_API.html",
    "href": "es/04_API.html",
    "title": "API reference",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision."
  },
  {
    "objectID": "es/04_API.html#in_out.read_wrf_multi",
    "href": "es/04_API.html#in_out.read_wrf_multi",
    "title": "API reference",
    "section": "in_out.read_wrf_multi",
    "text": "in_out.read_wrf_multi\nin_out.read_wrf_multi(files,list_no_vars,difHor=0,sign=1)\nRead a list of wrfout files for the variables selected.\n\nParameters:\n\nfiles : List of wrfout files\nlist_no_vars : List of variables to be delated\ndifHor : String with the hours t\nsign: -1 or 1 according to the difference\n\n\n\nReturns\n\nfig (matplotlib.figure.Figure)\nax (matplotlib.axes.Axes)"
  },
  {
    "objectID": "es/04_API.html#in_out.read_wrf_single",
    "href": "es/04_API.html#in_out.read_wrf_single",
    "title": "API reference",
    "section": "in_out.read_wrf_single",
    "text": "in_out.read_wrf_single\nin_out.ds_wrf_single(file,list_no_vars,difHor=0,sign=1)\nRead a list of wrfout files for the variables selected.\n\nParameters:\n\nfile : List of wrfout files\nlist_no_vars : List of variables to be delated\ndifHor : String with the hours t\nsign: -1 or 1 according to the difference\n\n\n\nReturns\n\nfig (matplotlib.figure.Figure)\nax (matplotlib.axes.Axes)"
  },
  {
    "objectID": "es/04_API.html#in_out.extract_station_wrf",
    "href": "es/04_API.html#in_out.extract_station_wrf",
    "title": "API reference",
    "section": "in_out.extract_station_wrf",
    "text": "in_out.extract_station_wrf\nin_out.extract_station_wrf(out,station,lon_col, lat_col, name_col, output_format='netcdf')\nExtracts data from a WRF output file using station coordinates provided in a CSV or shapefile.\n\nParameters:\n\nout (nc): the wrf outfile already laoded.\nstation (str): Path to the CSV or shapefile containing station coordinates.\nlon_col (str): Name of the column containing longitude values.\nlat_col (str): Name of the column containing latitude values.\nname_col (str): Name of the column containing station names.\noutput_format (str, optional): Output format (‘netcdf’ or ‘dataframe’). Defaults to ‘netcdf’.\n\n\n\nReturns\n\nfig (matplotlib.figure.Figure)\nax (matplotlib.axes.Axes)"
  },
  {
    "objectID": "es/04_API.html#met_vars.calc_pp",
    "href": "es/04_API.html#met_vars.calc_pp",
    "title": "API reference",
    "section": "met_vars.calc_pp",
    "text": "met_vars.calc_pp\nmet_diag.calc_pp(ds, elim=False)\nde-acumulate the rainfall and save it as PP.\n\nParameters:\n\nds (nc): dataset with the variables RAINC, RAINNC and RAINSH already loaded.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "es/04_API.html#met_vars.calc_wsp",
    "href": "es/04_API.html#met_vars.calc_wsp",
    "title": "API reference",
    "section": "met_vars.calc_wsp",
    "text": "met_vars.calc_wsp\nmet_diag.calc_wsp(ds, elim=False)\ncalculate the wind speed.\n\nParameters:\n\nds (nc): dataset with the variables U10 and V10 already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "es/04_API.html#met_vars.calc_pres",
    "href": "es/04_API.html#met_vars.calc_pres",
    "title": "API reference",
    "section": "met_vars.calc_pres",
    "text": "met_vars.calc_pres\nmet_diag.calc_pres(ds, elim=False)\ncalculate the total atmospheric pressure and save it as Presion.\n\nParameters:\n\nds (nc): dataset with the variables P, PB already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "es/04_API.html#met_vars.calc_tp",
    "href": "es/04_API.html#met_vars.calc_tp",
    "title": "API reference",
    "section": "met_vars.calc_tp",
    "text": "met_vars.calc_tp\nmet_diag.calc_tp(ds, elim=False)\ncalculate the potential temperature and save it as TPo.\n\nParameters:\n\nds (nc): dataset with the variable T already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "es/04_API.html#met_vars.calc_qe",
    "href": "es/04_API.html#met_vars.calc_qe",
    "title": "API reference",
    "section": "met_vars.calc_qe",
    "text": "met_vars.calc_qe\nmet_diag.calc_qe(ds, elim=False)\ncalculate the specific humidity and save it as QE.\n\nParameters:\n\nds (nc): dataset with the variable QVAPOR already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "es/04_API.html#spatial_scales.vert_levs",
    "href": "es/04_API.html#spatial_scales.vert_levs",
    "title": "API reference",
    "section": "spatial_scales.vert_levs",
    "text": "spatial_scales.vert_levs\nspatial_scales.vert_levs(ds,varis,lvls=None):\nInterpolate vertical levels to a pressure variable\n\nParameters:\n\nds (nc): dataset already loaded.\nvaris (list): list of vertical variables to interpolate.\nlvls (list): list of levels to be interpolated, if none provided, it will use [1000,975,950,925,900,850,800,700,600,500,400,300,200] as default.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "es/04_API.html#temp_scales.dmy_var",
    "href": "es/04_API.html#temp_scales.dmy_var",
    "title": "API reference",
    "section": "temp_scales.dmy_var",
    "text": "temp_scales.dmy_var\ntemp_scales.dmy_var(ds,tiempo=None ,accum=None, avg=None, mediana=None):\nConvert hourly (default wrf out) time to any acceptable by resample function.\n\nParameters:\n\nds : Dataset loaded\ntiempo : Time accepted by resample\naccum : List of variables who need sum\navg : if True use the mean function\nmediana : if True use the median function\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "es/04_API.html#temp_scales.monthly_clim",
    "href": "es/04_API.html#temp_scales.monthly_clim",
    "title": "API reference",
    "section": "temp_scales.monthly_clim",
    "text": "temp_scales.monthly_clim\ntemp_scales.monthly_clim(ds, stat=None, time_slice=None):\nConvert a Dataset to monthly climatology.\n\nParameters:\n\nds : Dataset loaded\nstat : Mean or median\ntime_slice : use the slice(ini,fin)\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "es/04_API.html#temp_scales.daily_clim",
    "href": "es/04_API.html#temp_scales.daily_clim",
    "title": "API reference",
    "section": "temp_scales.daily_clim",
    "text": "temp_scales.daily_clim\ntemp_scales.daily_clim(ds, var):\nGenerate daily climatology using moving window (mw) each 15 days.\n\nParameters:\n\nds : Dataset loaded\nvar : str with the variable’s name\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "es/06_references.html",
    "href": "es/06_references.html",
    "title": "References",
    "section": "",
    "text": "⚠️ Actualizando documentación / Updating documentation (v1 → v2)\n  Algunos contenidos pueden estar en revisión · Some sections may be under revision.\n\n\n\n\n\n\nReferences"
  }
]