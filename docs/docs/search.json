[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Getting Started",
    "section": "",
    "text": "Getting Started"
  },
  {
    "objectID": "index.html#what-is-scahpy",
    "href": "index.html#what-is-scahpy",
    "title": "Getting Started",
    "section": "What is SCAHpy?",
    "text": "What is SCAHpy?\nSCAHpy is an open-source Python package developed as a post-processing tool for the atmospheric, oceanic, and hydrological components of the regional Earth System Model covering the Peruvian territory and the Pacific Ocean. This model, named IGP-RESM-COW v1, was implemented by the Geophysical Institute of Peru (IGP) under the basis of the atmospheric WRF model, the oceanic CROCO model and the coupler OASIS."
  },
  {
    "objectID": "index.html#why-is-scahpy",
    "href": "index.html#why-is-scahpy",
    "title": "Getting Started",
    "section": "Why is SCAHpy?",
    "text": "Why is SCAHpy?\nThe Python package SCAHpy was created to address the significant challenge posed by the processing of data generated by the IGP-RESM-COW model. This model, with its atmospheric component based on the WRF model, produces massive amounts of data during simulations, which require considerable time for post-processing. SCAHpy streamlines this process by homogenizing coordinates and dimensions, ensuring compatibility and facilitating data analysis. By simplifying data handling and preparation."
  },
  {
    "objectID": "index.html#how-to-use-scahpy",
    "href": "index.html#how-to-use-scahpy",
    "title": "Getting Started",
    "section": "How to use SCAHpy?",
    "text": "How to use SCAHpy?\nSCAHpy can be used as a standalone package, to get more details go to Usage and tutorials.\n\n\n\n\n\n\nNote\n\n\n\nSCAHpy has been developed and tested using IGP-RESM-COW model outputs. However, it is designed to work with any WRF outputs. We are open to contributions from users!\n\n\n\nGetting Started\n\nInstallation\nUsage\n\n\n\nTutorials\n\nTutorial: Reading Single Files\nTutorial: Reading Multiple Files\nTutorial: Pressure Levels Variables\n\n\n\nHelp & Reference\n\nAPI References\nContributing"
  },
  {
    "objectID": "01_install.html#required-dependencies",
    "href": "01_install.html#required-dependencies",
    "title": "Installation",
    "section": "Required dependencies:",
    "text": "Required dependencies:\n\nPython &gt;= 3.9\nxarray\nwrf-python\nnetCDF4\nDask"
  },
  {
    "objectID": "01_install.html#optional-dependencies",
    "href": "01_install.html#optional-dependencies",
    "title": "Installation",
    "section": "Optional dependencies:",
    "text": "Optional dependencies:\nFor optimal performance, it is highly recommended that you install the following dependencies:\n\nbottleneck\nCartopy\nIPython\ngeopandas\nJupyterLab"
  },
  {
    "objectID": "01_install.html#step-by-step-instructions",
    "href": "01_install.html#step-by-step-instructions",
    "title": "Installation",
    "section": "Step-by-step instructions",
    "text": "Step-by-step instructions\nThese instructions should function in most operating systems, including Windows, macOS, and Linux, as Conda and Miniforge are designed to be cross-platform. However, there might be slight differences in the installation process or command syntax depending on the operating system.\nTo ensure clarity and compatibility across all operating systems, consider the following:\n\nWindows:\n\nUsers might need to open the terminal or command prompt as an administrator to execute some commands.\nPaths in the terminal should use backslashes (\\) instead of forward slashes (/).\n\nmacOS:\n\nUsers may need to install command-line developer tools if they haven’t done so already. This can be done by running xcode-select --install in the terminal.\nEnsure that users have permission to execute scripts and install packages.\n\nLinux:\n\nSome Linux distributions might require additional dependencies or configurations for Conda or Miniforge to work properly. It’s advisable to consult the documentation specific to the Linux distribution being used.\n\n\n\nUsing Conda\n\nDownload and Install Miniforge:\n\nBefore installing scahpy, you need to ensure that you have Conda installed on your system. Miniforge is a minimal distribution of Conda that includes essential tools for package management.\nGo to the Miniforge GitHub page and follow the instructions to download and install Miniforge suitable for your operating system.\n\nCreate a New Conda Environment and Install SCAHpy:\n\nOnce Conda is installed, you can create a new Conda environment specifically for scahpy and its dependencies. To do this, you’ll use an environment file called environment.yml, which contains a list of packages and their versions required for scahpy to function properly.\nDownload the environment.yml file from the SCAHpy GitHub repository.\nOpen a terminal or command prompt and navigate to the directory where the environment.yml file is located.\nRun the following command to create a new Conda environment named scahpy_env and install all the packages listed in the environment.yml file:\nconda env create --file environment.yml -n scahpy_env\nThis command will create a new Conda environment named scahpy_env and install all the required dependencies listed in the environment.yml file into this environment.\nOnce the environment is created, activate it using the following command:\nconda activate scahpy_env\n\n\nBy following these steps, you’ll have scahpy and all its dependencies installed and ready to use in your Conda environment.\n\n\nUsing Mamba\n\nDownload and Install Mamba: Before installing scahpy, you need to ensure that you have Mamba installed on your system. Mamba is a package manager for Conda environments and can be installed via Miniforge, which is a minimal distribution of Conda that includes Mamba.\n\nGo to the Miniforge GitHub page and follow the instructions to download and install Miniforge suitable for your operating system.\n\nInstall SCAHpy and Dependencies:\n\nThe easiest and recommended way to install scahpy along with its required dependencies is by using an environment file called environment.yml. This file contains a list of packages and their versions that are needed for scahpy to function properly.\nDownload the environment.yml file from the SCAHpy GitHub repository.\nOpen a terminal or command prompt and navigate to the directory where the environment.yml file is located.\nRun the following command to create a new Conda environment named scahpy_env and install all the packages listed in the environment.yml file:\nmamba env create --file environment.yml -n scahpy_env\nThis command will create a new Conda environment named scahpy_env and install all the required dependencies listed in the environment.yml file into this environment.\n\n\nBy following these steps, you’ll have scahpy and all its dependencies installed and ready to use in your Python environment.\n\n\nUsing pip\n\nFirst, ensure you have Python and pip installed on your system. You can download and install Python from the official Python website, which usually includes pip by default.\nThe easiest way to install scahpy and its dependencies is by creating a virtual environment and installing from a requirements file. Open a terminal or command prompt, then run the following commands:\n\n# Create a virtual environment (optional but recommended)\npython -m venv scahpy_env\n# Activate the virtual environment\n\n# On Windows\nscahpy_env\\Scripts\\activate\n# On macOS/Linux\nsource scahpy_env/bin/activate\n\n# Install scahpy and dependencies from requirements.txt\npip install -r requirements.txt\nIn this example, requirements.txt is a file containing a list of dependencies including scahpy. You would need to provide or generate this file yourself, listing all necessary packages and their versions: wrf-python, netCDF4, xarray, numpy, pandas, matplotlib, cartopy, geopandas, datetime, scahpy."
  },
  {
    "objectID": "02_use.html",
    "href": "02_use.html",
    "title": "Usage",
    "section": "",
    "text": "Example Usage of scahpy Package"
  },
  {
    "objectID": "02_use.html#importing-the-package",
    "href": "02_use.html#importing-the-package",
    "title": "Usage",
    "section": "Importing the Package",
    "text": "Importing the Package\nTo import all the modules in scahpy we can use the * as for example:\nfrom scahpy import *\nTo import specific modules from the package, we can specify their names:\nfrom scahpy import in_out, met_diag"
  },
  {
    "objectID": "02_use.html#reading-multiple-wrf-outs",
    "href": "02_use.html#reading-multiple-wrf-outs",
    "title": "Usage",
    "section": "Reading Multiple WRF outs",
    "text": "Reading Multiple WRF outs\n# Example: Reading and processing multiple WRF datasets\nsfc = in_out._drop_wrf_vars('/datos/wrfout_d01_2024-01-01_03:00:00',['RAINC', 'RAINNC', 'RAINSH', 'U10', 'V10', 'SSTSK'])\nfiles = sorted(glob.glob('/datos/wrfout_d01*'))\nds = in_out.ds_wrf_multi(files, sfc, '5 hours', -1)"
  },
  {
    "objectID": "02_use.html#calculating-precipitation",
    "href": "02_use.html#calculating-precipitation",
    "title": "Usage",
    "section": "Calculating Precipitation",
    "text": "Calculating Precipitation\nscahpy has a module called met_diag designed specifically for calculating various diagnostic variables, such as precipitation, using the calc_pp function.\n# Example: Calculating precipitation using diagnostics module\nds2 = met_diag.calc_pp(ds,vars_to_sum=['RAINC', 'RAINNC', 'RAINSH'],True)"
  },
  {
    "objectID": "03_tutorial_01.html#step-1-reading-wrf-data",
    "href": "03_tutorial_01.html#step-1-reading-wrf-data",
    "title": "Reading a Single File",
    "section": "Step 1: Reading WRF Data",
    "text": "Step 1: Reading WRF Data\nWe begin by setting the absolute path of the output file we intend to work with and assign it to a variable, in this case, file_name.\nfile_name = '/data/datos/COW/OUT_DIAG_WRF/wrfouts/wrfout_d01_2023-03-10_03:00:00'\nSince we have the flexibility to specify which variables to exclude when reading netCDF files using the drop_variables argument (see xarray functions open_dataset and open_mfdataset), we leverage the _drop_wrf_vars function. This function takes the list of variables we require and generates a list containing all variables present in the output file, subsequently removing those we are not interested in (such as ‘RAINC’, ‘RAINNC’, ‘RAINSH’, ‘U10’, ‘V10’, ‘SSTSK’).\nvars = in_out._drop_wrf_vars(file_name, ['RAINC', 'RAINNC', 'RAINSH', 'U10', 'V10', 'SSTSK'])\nSubsequently, we utilize the ds_wrf_single function to selectively read the variables of interest. This function accepts the input path (file_name in this case), the list of variables to be excluded (vars), any required time difference (e.g., '5 hours'), and the corresponding sign of the time difference (-1 for negative, 1 for positive). The outcome is an xarray.Dataset containing longitude, latitude, time, and the specified variables. Optionally, you can designate a save path to export the netCDF.\nds = in_out.ds_wrf_single(file_name, vars, '5 hours', -1)"
  },
  {
    "objectID": "03_tutorial_01.html#step-2-calculating-precipitation-and-wind-speed",
    "href": "03_tutorial_01.html#step-2-calculating-precipitation-and-wind-speed",
    "title": "Reading a Single File",
    "section": "Step 2: Calculating Precipitation and Wind Speed",
    "text": "Step 2: Calculating Precipitation and Wind Speed\nIn this step, we will utilize the met_diag module to calculate precipitation (calc_pp), wind speed (calc_wsp), and convert sea surface temperature from Kelvin to Celsius (calc_celsius).\nThe calc_pp function has an optional argument vars_to_sum, allowing users to specify which variables to sum to obtain total precipitation. If no variables are provided, it will default to summing the three variables: RAINC, RAINNC, and RAINSH.\nds_sfc = met_diag.calc_pp(ds, vars_to_sum=['RAINC', 'RAINNC', 'RAINSH'], elim=True)\nds_sfc = met_diag.calc_wsp(ds_sfc, elim=False)\nds_sfc = met_diag.calc_celsius(ds_sfc, 'SSTSK')\nBy running these commands, we ensure that our dataset ds_sfc now contains calculated precipitation, wind speed, and sea surface temperature in Celsius, ready for further analysis or visualization."
  },
  {
    "objectID": "03_tutorial_01.html#step-3-plotting-precipitation-maps",
    "href": "03_tutorial_01.html#step-3-plotting-precipitation-maps",
    "title": "Reading a Single File",
    "section": "Step 3: Plotting Precipitation Maps",
    "text": "Step 3: Plotting Precipitation Maps\nNext, we’ll generate precipitation maps with SST contours and wind vectors using the map_pp_uv10_sst function from the map_plots module. This function takes the rainfall (PP) variable as input, followed by the dataset with SST and wind components, precipitation levels, SST contours, optional shapefile, exportation settings, output path, temporal scale (‘H’ for hourly, ‘D’ for daily, ‘M’ for monthly, ‘Y’ for yearly), vector speed, and plot extent ([x1, x2, y1, y2]).\n# Example usage\nprecipitation_levels = [1, 2, 3, 5, 7, 11, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\nsst_contour_levels = [26, 27, 28]\n\nmap_plots.map_pp_uv10_sst(ds_sfc['PP'], ds_sfc, precipitation_levels, sst_contour_levels, shapefile=None, \n                           output_path='.', save_maps=True, freq='H',\n                           quiverkey_speed=10, extent=None)"
  },
  {
    "objectID": "03_tutorial_02.html#step-1-reading-wrf-data",
    "href": "03_tutorial_02.html#step-1-reading-wrf-data",
    "title": "Reading Multiple File",
    "section": "Step 1: Reading WRF Data",
    "text": "Step 1: Reading WRF Data\nWe initiate the process by listing all the files we want to read using the glob package and assigning them to the variable list_files.\nlist_files = sorted(glob.glob('/data/datos/COW/OUT_DIAG_WRF/wrfouts/wrfout_d01_*'))\nGiven the capability to specify excluded variables when reading netCDF files using the drop_variables argument (refer to xarray functions open_dataset and open_mfdataset), we utilize the _drop_wrf_vars function from the module in_out. This function takes the list of variables we require and generates a list containing all variables present in the output file, subsequently removing those we are not interested in (such as ‘RAINC’, ‘RAINNC’, ‘RAINSH’, ‘U10’, ‘V10’, ‘SSTSK’). For this purpose, we use the first file from our list of files, assigning it to the variable vars.\nvars = in_out._drop_wrf_vars(list_files[0], ['RAINC', 'RAINNC', 'RAINSH', 'U10', 'V10', 'SSTSK'])\nSubsequently, we utilize the ds_wrf_multi function to selectively read the variables of interest. This function accepts the input path (file_name in this case), the list of variables to be excluded (vars), any required time difference (e.g., '5 hours'), and the corresponding sign of the time difference (-1 for negative, 1 for positive). The outcome is an xarray.Dataset containing longitude, latitude, time, and the specified variables. Optionally, you can designate a save path to export the netCDF.\nds = in_out.ds_wrf_multi(list_files, vars, '5 hours', -1)"
  },
  {
    "objectID": "03_tutorial_02.html#step-2-calculating-precipitation-and-wind-speed",
    "href": "03_tutorial_02.html#step-2-calculating-precipitation-and-wind-speed",
    "title": "Reading Multiple File",
    "section": "Step 2: Calculating Precipitation and Wind Speed",
    "text": "Step 2: Calculating Precipitation and Wind Speed\nIn this step, we will utilize the met_diag module to calculate precipitation (calc_pp), wind speed (calc_wsp), and convert sea surface temperature from Kelvin to Celsius (calc_celsius).\nThe calc_pp function has an optional argument vars_to_sum, allowing users to specify which variables to sum to obtain total precipitation. If no variables are provided, it will default to summing the three variables: RAINC, RAINNC, and RAINSH.\nds_sfc = met_diag.calc_pp(ds, vars_to_sum=['RAINC', 'RAINNC', 'RAINSH'], elim=True)\nds_sfc = met_diag.calc_wsp(ds_sfc, elim=False)\nds_sfc = met_diag.calc_celsius(ds_sfc, 'SSTSK')\nBy running these commands, we ensure that our dataset ds_sfc now contains calculated precipitation, wind speed, and sea surface temperature in Celsius, ready for further analysis or visualization."
  },
  {
    "objectID": "03_tutorial_02.html#step-3-agregating-the-data",
    "href": "03_tutorial_02.html#step-3-agregating-the-data",
    "title": "Reading Multiple File",
    "section": "Step 3: Agregating the data",
    "text": "Step 3: Agregating the data\ndd = temp_scales.dmy_var(ds_sfc_, tiempo='1D', accum=['PP'], avg=['U10', 'V10'], mediana=['SSTSK'])"
  },
  {
    "objectID": "03_tutorial_02.html#step-4-plotting-precipitation-maps",
    "href": "03_tutorial_02.html#step-4-plotting-precipitation-maps",
    "title": "Reading Multiple File",
    "section": "Step 4: Plotting Precipitation Maps",
    "text": "Step 4: Plotting Precipitation Maps\nNext, we’ll generate precipitation maps with SST contours and wind vectors using the map_pp_uv10_sst function from the map_plots module. This function takes the rainfall (PP) variable as input, followed by the dataset with SST and wind components, precipitation levels, SST contours, optional shapefile, exportation settings, output path, temporal scale (‘H’ for hourly, ‘D’ for daily, ‘M’ for monthly, ‘Y’ for yearly), vector speed, and plot extent ([x1, x2, y1, y2]).\n# Example usage\nprecipitation_levels = [1, 2, 3, 5, 7, 11, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\nsst_contour_levels = [26, 27, 28]\n\nmap_plots.map_pp_uv10_sst(ds_sfc['PP'], ds_sfc, precipitation_levels, sst_contour_levels, shapefile=None, \n                           output_path='.', save_maps=True, freq='H',\n                           quiverkey_speed=10, extent=None)"
  },
  {
    "objectID": "03_tutorial_03.html#step-1-reading-wrf-data",
    "href": "03_tutorial_03.html#step-1-reading-wrf-data",
    "title": "Pressure levels variables",
    "section": "Step 1: Reading WRF Data",
    "text": "Step 1: Reading WRF Data\nFirst, we need to read the WRF data using the in_out module in the scahpy package. We’ll drop unnecessary variables and select a single WRF dataset.\nfrom scahpy import *\nimport glob\n\nsfc = in_out._drop_wrf_vars('/data/datos/COW/OUT_DIAG_WRF/wrfouts/wrfout_d01_2023-03-10_03:00:00',['U', 'W', 'P', 'PB', 'QVAPOR'])\nfiles = sorted(glob.glob('/data/datos/COW/OUT_DIAG_WRF/wrfouts/wrfout_d01_2023-03-1*'))\nds = in_out.ds_wrf_multi(files, sfc, '5 hours', -1)"
  },
  {
    "objectID": "03_tutorial_03.html#step-2-calculating-precipitation-and-wind-speed",
    "href": "03_tutorial_03.html#step-2-calculating-precipitation-and-wind-speed",
    "title": "Pressure levels variables",
    "section": "Step 2: Calculating Precipitation and Wind Speed",
    "text": "Step 2: Calculating Precipitation and Wind Speed\nNow, let’s calculate precipitation using the met_diag module.\nds_vert = met_diag.calc_qe(ds, elim=True)\nds_vert = met_diag.calc_pres(ds_vert, elim=True)"
  },
  {
    "objectID": "03_tutorial_03.html#step-3-agregating-the-data",
    "href": "03_tutorial_03.html#step-3-agregating-the-data",
    "title": "Pressure levels variables",
    "section": "Step 3: Agregating the data",
    "text": "Step 3: Agregating the data\ndd = temp_scales.dmy_var(ds_vert, tiempo='1D', avg=['Presion','U','W','QE'])"
  },
  {
    "objectID": "03_tutorial_03.html#step-4-plotting",
    "href": "03_tutorial_03.html#step-4-plotting",
    "title": "Pressure levels variables",
    "section": "Step 4: Plotting",
    "text": "Step 4: Plotting\nNow, let’s create precipitation maps for selected months using the cross_section_yz function.\n# Example usage\nThis tutorial guides you through the steps of reading WRF data, calculating precipitation, performing temporal aggregation, and creating precipitation maps using the scahpy package."
  },
  {
    "objectID": "04_API.html#in_out.ds_wrf_multi",
    "href": "04_API.html#in_out.ds_wrf_multi",
    "title": "API reference",
    "section": "in_out.ds_wrf_multi",
    "text": "in_out.ds_wrf_multi\nin_out.ds_wrf_multi(files,list_no_vars,difHor=0,sign=1)\nRead a list of wrfout files for the variables selected.\n\nParameters:\n\nfiles : List of wrfout files\nlist_no_vars : List of variables to be delated\ndifHor : String with the hours t\nsign: -1 or 1 according to the difference\n\n\n\nReturns\n\nfig (matplotlib.figure.Figure)\nax (matplotlib.axes.Axes)"
  },
  {
    "objectID": "04_API.html#in_out.ds_wrf_single",
    "href": "04_API.html#in_out.ds_wrf_single",
    "title": "API reference",
    "section": "in_out.ds_wrf_single",
    "text": "in_out.ds_wrf_single\nin_out.ds_wrf_single(file,list_no_vars,difHor=0,sign=1)\nRead a list of wrfout files for the variables selected.\n\nParameters:\n\nfile : List of wrfout files\nlist_no_vars : List of variables to be delated\ndifHor : String with the hours t\nsign: -1 or 1 according to the difference\n\n\n\nReturns\n\nfig (matplotlib.figure.Figure)\nax (matplotlib.axes.Axes)"
  },
  {
    "objectID": "04_API.html#in_out.extract_station_wrf",
    "href": "04_API.html#in_out.extract_station_wrf",
    "title": "API reference",
    "section": "in_out.extract_station_wrf",
    "text": "in_out.extract_station_wrf\nin_out.extract_station_wrf(out,station,lon_col, lat_col, name_col, output_format='netcdf')\nExtracts data from a WRF output file using station coordinates provided in a CSV or shapefile.\n\nParameters:\n\nout (nc): the wrf outfile already laoded.\nstation (str): Path to the CSV or shapefile containing station coordinates.\nlon_col (str): Name of the column containing longitude values.\nlat_col (str): Name of the column containing latitude values.\nname_col (str): Name of the column containing station names.\noutput_format (str, optional): Output format (‘netcdf’ or ‘dataframe’). Defaults to ‘netcdf’.\n\n\n\nReturns\n\nfig (matplotlib.figure.Figure)\nax (matplotlib.axes.Axes)"
  },
  {
    "objectID": "04_API.html#met_diag.calc_pp",
    "href": "04_API.html#met_diag.calc_pp",
    "title": "API reference",
    "section": "met_diag.calc_pp",
    "text": "met_diag.calc_pp\nmet_diag.calc_pp(ds, elim=False)\nde-acumulate the rainfall and save it as PP.\n\nParameters:\n\nds (nc): dataset with the variables RAINC, RAINNC and RAINSH already loaded.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "04_API.html#met_diag.calc_wsp",
    "href": "04_API.html#met_diag.calc_wsp",
    "title": "API reference",
    "section": "met_diag.calc_wsp",
    "text": "met_diag.calc_wsp\nmet_diag.calc_wsp(ds, elim=False)\ncalculate the wind speed.\n\nParameters:\n\nds (nc): dataset with the variables U10 and V10 already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "04_API.html#met_diag.calc_pres",
    "href": "04_API.html#met_diag.calc_pres",
    "title": "API reference",
    "section": "met_diag.calc_pres",
    "text": "met_diag.calc_pres\nmet_diag.calc_pres(ds, elim=False)\ncalculate the total atmospheric pressure and save it as Presion.\n\nParameters:\n\nds (nc): dataset with the variables P, PB already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "04_API.html#met_diag.calc_tp",
    "href": "04_API.html#met_diag.calc_tp",
    "title": "API reference",
    "section": "met_diag.calc_tp",
    "text": "met_diag.calc_tp\nmet_diag.calc_tp(ds, elim=False)\ncalculate the potential temperature and save it as TPo.\n\nParameters:\n\nds (nc): dataset with the variable T already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "04_API.html#met_diag.calc_qe",
    "href": "04_API.html#met_diag.calc_qe",
    "title": "API reference",
    "section": "met_diag.calc_qe",
    "text": "met_diag.calc_qe\nmet_diag.calc_qe(ds, elim=False)\ncalculate the specific humidity and save it as QE.\n\nParameters:\n\nds (nc): dataset with the variable QVAPOR already loaded with coordinates already processed.\nelim (bool): False (default) keep the old and new variables, True keep only the new variable.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "04_API.html#spatial_scales.vert_levs",
    "href": "04_API.html#spatial_scales.vert_levs",
    "title": "API reference",
    "section": "spatial_scales.vert_levs",
    "text": "spatial_scales.vert_levs\nspatial_scales.vert_levs(ds,varis,lvls=None):\nInterpolate vertical levels to a pressure variable\n\nParameters:\n\nds (nc): dataset already loaded.\nvaris (list): list of vertical variables to interpolate.\nlvls (list): list of levels to be interpolated, if none provided, it will use [1000,975,950,925,900,850,800,700,600,500,400,300,200] as default.\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "04_API.html#temp_scales.dmy_var",
    "href": "04_API.html#temp_scales.dmy_var",
    "title": "API reference",
    "section": "temp_scales.dmy_var",
    "text": "temp_scales.dmy_var\ntemp_scales.dmy_var(ds,tiempo=None ,accum=None, avg=None, mediana=None):\nConvert hourly (default wrf out) time to any acceptable by resample function.\n\nParameters:\n\nds : Dataset loaded\ntiempo : Time accepted by resample\naccum : List of variables who need sum\navg : if True use the mean function\nmediana : if True use the median function\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "04_API.html#temp_scales.monthly_clim",
    "href": "04_API.html#temp_scales.monthly_clim",
    "title": "API reference",
    "section": "temp_scales.monthly_clim",
    "text": "temp_scales.monthly_clim\ntemp_scales.monthly_clim(ds, stat=None, time_slice=None):\nConvert a Dataset to monthly climatology.\n\nParameters:\n\nds : Dataset loaded\nstat : Mean or median\ntime_slice : use the slice(ini,fin)\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "04_API.html#temp_scales.daily_clim",
    "href": "04_API.html#temp_scales.daily_clim",
    "title": "API reference",
    "section": "temp_scales.daily_clim",
    "text": "temp_scales.daily_clim\ntemp_scales.daily_clim(ds, var):\nGenerate daily climatology using moving window (mw) each 15 days.\n\nParameters:\n\nds : Dataset loaded\nvar : str with the variable’s name\n\n\n\nReturns\n\nnetcdf xarray.Dataset"
  },
  {
    "objectID": "05_contrib.html",
    "href": "05_contrib.html",
    "title": "Contributing",
    "section": "",
    "text": "All types of crontributions, bugs, feedbacks are welcome!\nReport bugs and submit feedback at Github Issues."
  },
  {
    "objectID": "02_use.html#reading-wrf-outputs-files",
    "href": "02_use.html#reading-wrf-outputs-files",
    "title": "Usage",
    "section": "Reading WRF outputs files",
    "text": "Reading WRF outputs files\nThe WRF model can generate outputs either with one time per file or multiple times in a single file. scahpy is capable of handling both scenarios. For reading multiple wrfout files, you can utilize the ds_wrf_multi function, while for reading a single file, you can use the ds_wrf_single function.\n# Example: Reading and processing multiple WRF datasets\nsfc = in_out._drop_wrf_vars('/datos/wrfout_d01_2024-01-01_03:00:00',['RAINC', 'RAINNC', 'RAINSH', 'U10', 'V10', 'SSTSK'])\nfiles = sorted(glob.glob('/datos/wrfout_d01*'))\nds = in_out.ds_wrf_multi(files, sfc, '5 hours', -1)"
  },
  {
    "objectID": "03_tutorial_02.html#step-3-aggregating-the-data",
    "href": "03_tutorial_02.html#step-3-aggregating-the-data",
    "title": "Reading Multiple File",
    "section": "Step 3: Aggregating the Data",
    "text": "Step 3: Aggregating the Data\nNow, we’ll aggregate the data to operate on a daily time scale instead of hourly. To achieve this, we’ll utilize the dmy_var function from the temp_scales module. This function takes an xarray.Dataset as input, where we specify the desired time scale (e.g., ‘1D’ for daily, ‘ME’ for monthly, ‘YE’ for yearly). Additionally, we can specify which variables should be aggregated by sum, average, or median by providing lists for each aggregation method.\ndd = temp_scales.dmy_var(ds_sfc, tiempo='1D', accum=['PP'], avg=['U10', 'V10'], mediana=['SSTSK'])\nBy executing this code, we’ll have our data aggregated to a daily time scale, with certain variables summed, averaged, or median-calculated according to our specifications."
  }
]